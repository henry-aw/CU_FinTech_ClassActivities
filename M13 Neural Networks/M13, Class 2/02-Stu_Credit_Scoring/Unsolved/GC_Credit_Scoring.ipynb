{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "pygments_lexer": "ipython3",
    "name": "python",
    "mimetype": "text/x-python",
    "npconvert_exporter": "python",
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "version": 3,
    "kernelspec": {
      "display_name": "Python (dev)",
      "language": "python",
      "name": "dev"
    },
    "file_extension": ".py",
    "nteract": {
      "version": "0.28.0"
    },
    "colab": {
      "name": "Credit_Scoring.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwNQBox7oVSw"
      },
      "source": [
        "# Credit Scoring\n",
        "\n",
        "In this activity, you will use a deep learning model to predict the credit scores of borrowers using alternative data.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Fintech opportunities in emerging economies are extremely large. There are billions of new consumers, with access to a digital wallet, who have a desire to get a lower interest rate loan. The trouble is, most of them don't have a credit score.\n",
        "\n",
        "An alternative data firm is therefore collecting data on emerging market consumers, from utility bills, to industry worked, to even responses to online surveys about good money habits. They've provided you this data, in order to build a model which can be use all of this information to provide a usable credit score for anyone interested in applying for a loan.\n",
        "\n",
        "The dataset contains `68` encoded features (columns from `0` to `67`), with all personal identifying information removed. The last two columns of the dataset (columns `68` and `69`) are preliminary credit score quality indicators that have been manually assigned by staff at the firm. (The firm thinks that if a model can be built for this labeled data, it can then be used to automatically make credit predictions about customers it hasn't gone through this labelling process with).\n",
        "\n",
        "1. Create a shallow (`1` hidden layer) and deep neural network (with two layers) to predict the geographical coordinates of the compositions represented in the data. Decide on your own how many neurons you will use on each hidden layer.\n",
        "\n",
        "2. Fit each model with at least `800` epochs, and setting `validation_split=0.3`.\n",
        "\n",
        "3. Compare the loss metrics for the two models.\n",
        "\n",
        "4. Compare train (loss) and test (val_loss) metrics for both models, and look for signs of overfitting.\n",
        "\n",
        "## Hint\n",
        "\n",
        "* Note that that there needs to be two regression outputs. Your model structure should reflect this.\n",
        "\n",
        "* When fitting the model, you can set the parameter `verbose=0` in the `fit()` method to mute the printing of each epoch's results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg_piOWxoVSz"
      },
      "source": [
        "# Initial imports\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufT50gjio0HN"
      },
      "source": [
        "# Upload credit_scores.csv to Colab\n",
        "from google.colab import files\n",
        "\n",
        "csv_file = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbs5NWHooVSz"
      },
      "source": [
        "# Read in data\n",
        "df = pd.read_csv(\"credit_scores.csv\", header=None)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inqnRyRsoVS0"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5KMQVUJoVS0"
      },
      "source": [
        "# Create the features set (X) and the target set (y)\n",
        "\n",
        "# The features dataset consists of columns 0 to 67\n",
        "X = df.iloc[:, 0:68]\n",
        "\n",
        "# The target consists of columns 68 and 69\n",
        "y = df.iloc[:, 68:70]\n",
        "\n",
        "# View data for the features set\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk22J9VBoVS0"
      },
      "source": [
        "# Scale the data of the features set using the StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "X = scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C80QF-3toVS0"
      },
      "source": [
        "## Create a shallow (`1` hidden layer) and deep neural network (with two layers) to predict the credit scores represented in the data. Decide on your own how many neurons you will use on each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwHBlCnhoVS1"
      },
      "source": [
        "# Create a shallow, 1 hidden layer, neural network\n",
        "\n",
        "# Instantiate an instance of the Sequential model\n",
        "nn = # YOUR CODE HERE\n",
        "\n",
        "# Create 1 hidden layer\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Create the output layer\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Compile the model \n",
        "# Set the parameters as mean_squared_error, adam, and mse.\n",
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc3Z46GyoVS1"
      },
      "source": [
        "## Step 2. Fit each model with at least `800` epochs, and setting `validation_split=0.3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srrQkN_WoVS1"
      },
      "source": [
        "# Fit the model\n",
        "model_1 = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aJHJUl4oVS1"
      },
      "source": [
        "## Create a deep neural network (with two layers) to predict the credit data. Decide on your own how many neurons you will use on each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L7prJ_yoVS1"
      },
      "source": [
        "# Create a deep neural network with 2 hidden layers\n",
        "\n",
        "# Instantiate an instance of the Sequential model\n",
        "dnn = # YOUR CODE HERE\n",
        "\n",
        "# Create the first hidden layer\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Create the second hidden layer\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Create the Output layer\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Compile the model \n",
        "# Set the parameters as mean_squared_error, adam, and mse.\n",
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDkcNLrdoVS2"
      },
      "source": [
        "## Step 2. Fit each model with at least `800` epochs, and setting `validation_split=0.3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJPkNa0oVS2"
      },
      "source": [
        "# Fit the model\n",
        "model_2 = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGgrY6gVoVS2"
      },
      "source": [
        "# Evaluate the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiy_4qhvoVS2"
      },
      "source": [
        "## Step 3: Compare the loss metrics for the two models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qolRTrK-oVS2"
      },
      "source": [
        "# Plot the loss function of the training results for the two models\n",
        "plt.plot(# YOUR CODE HERE)\n",
        "plt.plot(# YOUR CODE HERE)\n",
        "plt.title(\"loss_function - Training - 1 hidden layer Vs. 2 hidden layer\")\n",
        "plt.legend([\"1 hidden layer\", \"2 hidden layers\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtPp1OGhoVS3"
      },
      "source": [
        "## Step 4: Compare train (loss) and test (val_loss) metrics for both models, and look for signs of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfHAtn04oVS3"
      },
      "source": [
        "# Plot train vs test for the shallow neural net\n",
        "plt.plot(# YOUR CODE HERE)\n",
        "plt.plot(# YOUR CODE HERE)\n",
        "plt.title(\"loss_function - 1 hidden layer - Train Vs. Test\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h23faPtZoVS3"
      },
      "source": [
        "# Plot train vs test for the deep neural net\n",
        "plt.plot(# YOUR CODE HERE)\n",
        "plt.plot(# YOUR CODE HERE)\n",
        "plt.title(\"loss_function - 2 hidden layers - Train Vs. Test\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}